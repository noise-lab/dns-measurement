\section{Method}\label{sec:method}

In this section, we describe the metrics used, how these metrics are measured, and our experiment setup.

\subsection{Metrics}
To understand how non-mainstream resolvers function in relation to mainstream resolvers, we measure DNS query response times and latency to these resolvers. 

\subsubsection{DNS Query Response Time}
To collect accurate DNS query response time measurements, we modified a preexisting custom tool that was built to measure response times of Do53, DoT, and DoH queries~\cite{https://www.cs.princeton.edu/~ahounsel/publications/www20.pdf}.
The tool was modified to include a loop that allows for continuous measurements. 
With lists of specified recursors and domains, the tool prints data to a JSON file including information about the response time from each resolver to a domain. 
The three domains used in our experiment were Google.com, Netflix.com, and Facebook.com. 

\subsubsection{Latency}
To confirm our DNS Response Time measurements, we collected data on latency for each resolver. 
Lower latencies were expected for resolvers with low response times. 
To collect latency measuremtns, we performed ICMP ping to each of the resolvers. 


\subsection{Experiment Setup}
We employed MaxMind's GeoLite2 databases to geolocate each resolver and better understand how far each server is. 
That data was used to group the resolvers by location to make them more comparable. 
- Vantage points + description of hardware
- Network characteristics
- Description of tool
- Length of measurement
Our measurements were collected over the span of seven days. 
- Domains Used
We chose three popular domains: Google.com, a search engine, Netflix.com, a streaming service, and Facebook.com, a social media platform. 
- Measurements performed on a Debian operating system 


\subsection{Limitations}
	- We don't measure page load times 	